{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"ML/math/tensors/","title":"Tensors","text":""},{"location":"ML/math/tensors/#scalar-rank-0-tensor","title":"Scalar - Rank-0 Tensor","text":""},{"location":"ML/math/tensors/#definition-and-explanation","title":"Definition and Explanation","text":"<p>A simple numeric value such as 3 or -4.5. A scalar is a rank-0 tensor - i.e. it is a tensor with 0 dimensions - i.e. a tensor that contains only one number. They are called scalars because they scale vectors and matrices without changing the vector or matrix's direction. </p>"},{"location":"ML/math/tensors/#denotation","title":"Denotation","text":"<p>Denoted by an italic letter.</p> <p>\\({ \\it a} = 34\\) </p> <p>\\({\\it b} = -24.2\\)</p> <p>Note: In some texts, scalars are denoted using Greek lowercase letters.</p> <p>\\(\\lambda = 2\\)</p> <p>\\(\\gamma = 45.1\\)</p>"},{"location":"ML/math/tensors/#numpy-python-implementation","title":"NumPy / Python Implementation","text":"<p>In NumPy, a <code>np.array</code> of a single <code>float32</code> or <code>float64</code> is a scalar tensor.</p> <pre><code>&gt;&gt;&gt; x = np.array(12)\n&gt;&gt;&gt; x\n&gt;&gt;&gt; array(12)\n&gt;&gt;&gt; x.ndim\n&gt;&gt;&gt; 0\n</code></pre>"},{"location":"ML/math/tensors/#vector-rank-1-tensor","title":"Vector - Rank-1 Tensor","text":""},{"location":"ML/math/tensors/#definition-and-explanation_1","title":"Definition and Explanation","text":"<p>A vector is an array of numbers. It is a rank-1 tensor in that it has one axis. Geometrically,  a vector is a line defined by a magnitude (length) and direction. The dimensionality of the vector, is also the dimensionality of the coordinate system used to represent the vector. For instance, a 2 dimensional vector \\([1,2]\\) could be represented in a standard 2D XY grid.</p> <p>The definition of a vector does not include its starting point. In other words, the vector \\([1,2]\\) indicates a positive direction (right 1 unit, up 2 units), and a magnitude (\\(\\sqrt{5}\\)). This direction and magnitude tells use the location of the head (think of it as the arrow head) from the tail of the vector. However, the tail could start at any coordinate. A vector with its tail at the origin is said to start in the standard position.</p> <p>The tensor is said to be one-dimensional. The vector itself will also have dimensionality. For instance a point \\([2,3,0]\\) is said to be a 3-dimensional vector but a 1-dimensional tensor.</p> <p>The list of scalar values contained within a vector are called attributes.</p>"},{"location":"ML/math/tensors/#denotation_1","title":"Denotation","text":"<p>Denoted by a bold letter. The vector attributes are enclosed in square brackets.</p> <p>\\({\\bf a} = [0,1,-10]\\) </p> <p>\\({\\bf b} = [-24.2,0,15,18.2]\\)</p> <p>To reference a specific attribute within a vector, you use an italic value of the vector with an index like: \\({\\it a}^{(x)}\\). So for the examples above, we could reference the respective first and last attributes like so:</p> <p>\\({\\it a}^{(0)} = 0\\)</p> <p>\\({\\it b}^{(3)} = 18.2\\)</p>"},{"location":"ML/math/tensors/#numpy-python-implementation_1","title":"NumPy / Python Implementation","text":"<p>In NumPy, a <code>np.array</code> of an array of scalar values is a vector.</p> <pre><code>&gt;&gt;&gt; x = np.array([1,2,3,-77,14])\n&gt;&gt;&gt; x\n&gt;&gt;&gt; array([1,2,3,-77,14])\n&gt;&gt;&gt; x.ndim\n&gt;&gt;&gt; 1\n</code></pre>"},{"location":"ML/math/tensors/#vector-orientation","title":"Vector Orientation","text":"<p>A column vector is a is \\(m \\times 1\\) matrix, where consisting of a single column with \\(m\\) attributes. $$ Column \\ Vectors: \\begin{bmatrix}  2, \\\\  3,\\\\  4  \\end{bmatrix}, \\begin{bmatrix}  0, \\\\  -1 \\end{bmatrix} $$ A row vector is a \\(1\\times n\\) matrix consisting of a single row of \\(n\\) attributes. $$ Row \\ Vectors: [2,3,4], [0,-1] $$ Always assuming vectors are column vectors unless otherwise stated. Due to this, in text, a row vector will usually be denoted as being transposed. In other words, a row vector \\(\\bf v\\) would be written as \\(\\bf{v}^T\\). Also, in text, where we read horizontal lines, a column vector might be denoted as \\([1,2,3]^T\\). </p>"},{"location":"ML/math/vector_operations/","title":"Vector Operations","text":""},{"location":"ML/math/vector_operations/#transpose-operation","title":"Transpose Operation","text":"<p>You can transpose a column vector to a row vector and vice versa. This operation is denoted with a superscript T. $$ [4,2,0]^T =  \\begin{bmatrix} 4, \\\\  2,\\\\  0  \\end{bmatrix} $$</p> \\[ \\begin{bmatrix}  3, \\\\\\  -2,\\\\\\ 13  \\end{bmatrix}^T = [3, -2, 13] \\]"},{"location":"ML/math/vector_operations/#numpy-implementation","title":"NumPy Implementation","text":"<p>You simply use <code>.T</code> to transpose a vector.</p> <pre><code>v1 = np.array([[2, 3, 4]]) # row vector\nv2 = v1.T # Column vector\nprint(v2)\n\n&gt;&gt; array([[2],\n&gt;&gt;       [3],\n&gt;&gt;       [4]])\n</code></pre>"},{"location":"ML/math/vector_operations/#vector-addition-and-subtraction","title":"Vector Addition and Subtraction","text":"<p>Algebraically, vector addition and subtraction happens element-wise. Vectors need to be the same dimension.</p> \\[ [4, 5, 1, 0] + [-4, -3, 3, 10] = [0, 2, 4, 10] \\] \\[ \\begin{bmatrix}  4, \\\\\\ 2,\\\\\\ 0 \\end{bmatrix} - \\begin{bmatrix}  6, \\\\\\ -4,\\\\\\ -60 \\end{bmatrix} + \\begin{bmatrix}  2, \\\\\\ -5,\\\\\\ 40 \\end{bmatrix} = \\begin{bmatrix}  0, \\\\\\ 1,\\\\\\ 100 \\end{bmatrix} \\] <p>Geometrically, you can add up vectors by tip to tail and subtract vectors by multiplying one vector by -1 before adding up tip to tail. In the below image, we are adding vector A to vector B.</p> <p></p>"},{"location":"ML/math/vector_operations/#numpy-implementation_1","title":"NumPy Implementation","text":"<pre><code>v1 = np.array([[3,2,1]])\nv2 = np.array([[4,-8,12]])\nv3 = v2 + v1\nprint(v3)\n\n&gt;&gt; [[ 7 -6 13]]\n</code></pre>"},{"location":"ML/math/vector_operations/#vector-scalar-multiplication","title":"Vector Scalar Multiplication","text":"<p>When you multiply a vector by a scalar, you multiply each attribute by the scalar. $$ 3 \\times [2, 4, 5] = [6, 12, 15] $$ Geometrically, this changes the length but not the direction of the vector.</p>"},{"location":"ML/math/vector_operations/#numpy-implementation_2","title":"NumPy Implementation","text":"<pre><code>v1 = np.array([[3, 4, 5]])\nv2 = v1 * 3\nprint(v2)\n\n&gt;&gt; [[ 9 12 15]]\n</code></pre>"},{"location":"ML/math/vector_operations/#vector-dot-product","title":"Vector Dot Product","text":"<p>The dot product is extremely important for neural networks. Each unit within a layer will output a value by first taking the dot product between the weights and input, adding a bias and then applying an activation function.</p> <p>The dot product is a representation of how similar two vectors are. For a good explainer, using solar panels and Mario-Kart as an example, see this link.</p>"},{"location":"ML/math/vector_operations/#denotation","title":"Denotation","text":"<p>The dot product can be denoted in a few different ways, but the two I've encountered the most are: $$ {\\textbf a} ~ \\cdot ~ {\\textbf b} $$ or $$ {\\textbf a}^T{\\textbf b} $$</p>"},{"location":"ML/math/vector_operations/#calculation","title":"Calculation","text":"<p>To compute the product, you multiply corresponding attributes of equal dimension vectors, and then take the sum. $$ [1,4,7,7]~\\cdot~[2,4,3,2]~=~ 1\\times2~+~4\\times4~+7\\times3~+7\\times2~=~53 $$</p>"},{"location":"ML/math/vector_operations/#numpy-implementation_3","title":"NumPy Implementation","text":"<pre><code>v1 = np.array([3,2,1])\nv2 = np.array([4,-8,12])\nv3 = np.dot(v1, v2)\nprint(v3)\n\n&gt;&gt; 8\n</code></pre>"},{"location":"Setup/Git/git/","title":"Using Git with GitHub","text":""},{"location":"Setup/Git/git/#starting-from-zero","title":"Starting from Zero","text":"<p>I find the easiest way to get a GitHub repo / local repo pairing set up is to set up the Github remote repo first. You would do this at the very outset of the project, before you've written a line of code.</p>"},{"location":"Setup/Git/git/#setting-up-your-repo-on-github","title":"Setting up your repo on Github","text":"<p>Navigate to the repositories tab once logged into Github, and then click the green new button.</p> <p></p> <p>In the Create a new repository page, give the repo a memorable name. I follow the same naming convention that I use for my Linux directories, namely:</p> <ul> <li>All lower case</li> <li>Use '_' as delimiters</li> </ul> <p>Add a brief description. This description will appear below the about section of your repo's page.</p> <p>Set your repo to public or private.</p> <p>It's worth adding a README file. This will serve as the 'landing page' of your repo. Including information about what this repo contains is especially important if you plan on sharing with others.</p> <p>It's also worth adding the basic <code>.gitignore</code> template to the repo. You can always edit this file afterwards.</p> <p>Finally, if you plan on sharing your work, you can add a license. Choosealicense.com is a good place to start in figuring out what license you should use for your particular case.</p> <p>Once this is all done, click the create repository button.</p>"},{"location":"Setup/Git/git/#cloning-your-repo-to-your-local-computer","title":"Cloning your repo to your local computer","text":"<p>Once you have created your repo on Github, navigate to that repo, and click the green code button. Select SSH and then click the copy button directly to the right of the repo address. This will copy the repo address to your clipboard.</p> <p></p> <p>Go to you terminal and <code>cd</code> to the directory that will contain the repo. Note: The cloned repo will be a directory itself. You do not have to make a new directory. Once you are there use the command <code>git clone</code> followed by the address you copied in the last step:</p> <pre><code>thomas@ti83:~$ cd repos/ #move to the directory that will hold the repo\nthomas@ti83:~/repos$ git clone git@github.com:aarcThom/test_repo.git #clone the repo\nCloning into 'test_repo'...\nremote: Enumerating objects: 5, done.\nremote: Counting objects: 100% (5/5), done.\nremote: Compressing objects: 100% (4/4), done.\nremote: Total 5 (delta 0), reused 0 (delta 0), pack-reused 0\nReceiving objects: 100% (5/5), 13.96 KiB | 3.49 MiB/s, done.\nthomas@ti83:~/repos$\n</code></pre> <p>If all has gone according to plan, you should see an output similar to above. Assuming that your SSH key is already set up with GitHub, you can now commit and push to the remote Github repo like so:</p> <pre><code>thomas@ti83:~/repos$ cd test_repo/ # move to the cloned repo\nthomas@ti83:~/repos/test_repo$ touch testfile.txt # creating a test file\nthomas@ti83:~/repos/test_repo$ git add . # staging all changes\nthomas@ti83:~/repos/test_repo$ git commit -m \"Adding a test file\" #committing all staged changes\n[main b927402] Adding a test file\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 testfile.txt\nthomas@ti83:~/repos/test_repo$ git push # pushing the changes to the remote GitHub repo\nEnumerating objects: 4, done.\nCounting objects: 100% (4/4), done.\nDelta compression using up to 16 threads\nCompressing objects: 100% (2/2), done.\nWriting objects: 100% (3/3), 270 bytes | 270.00 KiB/s, done.\nTotal 3 (delta 1), reused 0 (delta 0), pack-reused 0\nremote: Resolving deltas: 100% (1/1), completed with 1 local object.\nTo github.com:aarcThom/test_repo.git\n   11cb475..b927402  main -&gt; main\nthomas@ti83:~/repos/test_repo$\n</code></pre>"},{"location":"Setup/Git/git/#you-have-already-set-up-a-project-virtual-environment-locally-creating-a-github-repo-from-the-command-line","title":"You have already set up a project / virtual environment locally - Creating a Github repo from the command line","text":"<p>You are going to use Github CLI - to fill in...</p>"},{"location":"Setup/Git/git_setup/","title":"Git Setup","text":""},{"location":"Setup/Git/git_setup/#creating-ssh-keys","title":"Creating  SSH Keys","text":"<p>\"SSH keys are an authentication method used to gain access to an encrypted connection between systems and then ultimately use that connection to manage the remote system.\" jumpcloud</p> <p>We will set up a SSH key on WSL to sync with our Github account.</p>"},{"location":"Setup/Git/git_setup/#check-if-you-already-have-an-ssh-key-saved-to-your-wsl-system","title":"Check if you  already have an SSH key saved to your WSL system","text":"<p>Use the command <code>ls</code> (list directory contents) to see if you have any keys saved in the default <code>.ssh</code> directory.</p> <pre><code>ls ~/.ssh\n</code></pre> <p>If no directory is found, or the directory is empty, you can proceed with the following steps. If you already have an SSH key, you can skip to the Adding your SSH key to Github section.</p>"},{"location":"Setup/Git/git_setup/#creating-a-new-ssh-key","title":"Creating a New SSH Key","text":"<p>To create a new SSH key, use the following command, replacing the \"your email\" with the email you set up in the previous <code>--global user.email</code> step.</p> <pre><code>ssh-keygen -t rsa -b 4096 -C \"your email\"\n</code></pre> <p>Press enter to accept the default location (<code>~/.ssh</code>).</p> <p>Enter a passphrase that you will remember. You will need to remember this passphrase.</p> <p>This command will create a private key <code>id_rsa</code> and a public key <code>id_rsa.pub</code> in the directory <code>~/.ssh</code>. To confirm this, you can type</p> <pre><code>ls ~/.ssh\n</code></pre> <p>Note: As of writing (2023-11-09), it appears that the ed25519 algorithm cannot be manage by the Ubuntu WSL2 ssh-agent. This is why we're using rsa instead. See this link</p>"},{"location":"Setup/Git/git_setup/#adding-a-ssh-key-to-github","title":"Adding a SSH Key to Github","text":"<p>First, we need to copy the contents of our public key file to our clipboard. To do so in WSL, we use the command</p> <pre><code>cat &lt;file we want to copy contents of&gt; | clip.exe\n</code></pre> <p>In Linux, <code>cat</code> (concatenate) reads a file and outputs the contents. A pipe <code>|</code> , in Linux, takes the output of one command and inputs into another command. And within WSL, <code>clip.exe</code> accesses Windows' clip board.</p> <p>So, to copy the contents of our public key, we can type</p> <pre><code>cat ~/.ssh/id_rsa.pub | clip.exe\n</code></pre> <p>Logged into Github, go to https://github.com/settings/keys . Click New SSH Key. Give the key a descriptive name. <code>Ctrl + V</code> into the key field. Click Add SSH key.</p>"},{"location":"Setup/Git/git_setup/#committing-changes-to-github","title":"Committing Changes to Github","text":"<p>After you've made some changes to files within a given local repo, you cant commit those changes with the following commands:</p> <pre><code>git add . # stage all files within the repo\ngit commit -m \"your message\" # commit changes with a message\ngit push #push changes to the github repo\n</code></pre> <p>You'll have to enter your SSH key password during this process, but we can alter this behavior so that we only need to enter our password once per terminal session.</p>"},{"location":"Setup/Git/git_setup/#adding-our-ssh-key-to-the-ssh-agent","title":"Adding our SSH Key to The SSH-Agent","text":"<p>Per terminal session, we can start a process, called <code>ssh-agent</code> that we can use as a key store. We add our key to the agent, and the agent will then automatically enter our key for us.</p> <p>First, check if <code>shh-agent</code> is running.</p> <pre><code>$ echo \"$SSH_AUTH_SOCK\" #check if it is running\n/tmp/ssh-XXXXXX0GNSeL/agent.602 # output like this = running. no output = not running\n</code></pre> <p>If it isn't running use the following command:</p> <pre><code>$ eval `ssh-agent` # enter this command\nAgent pid 631 #output should look like this\n</code></pre> <p>Assuming your key has the default name of <code>id_rsa</code> to add your SSH key to <code>ssh-agent</code>, use the following command. If you've given another name to your key, replace <code>id_rsa</code> with the name of your key.</p> <pre><code>$ ssh-add ~/.ssh/id_rsa\n</code></pre> <p>You will be prompted to enter your password. After you've done so, you won't need to enter your password again during the current terminal session.</p>"},{"location":"Setup/Git/git_setup/#partially-automating-the-process","title":"Partially Automating the Process","text":"<p>So far, we've done the following steps :</p> <ul> <li>We've generated a SSH Key Pair</li> <li>We've added the SSH public key to Github</li> <li>We've committed work to our repository</li> <li>We then added our SSH key to the ssh-agent so we don't have to re-type our password for every commit</li> </ul> <p>We can partially automate these last two steps. First, we can configure a commit-template to keep our commit messages consistent.  Second, Rather than typing our password every time we want to push to our repo, we can set up our system so that we only have to type our password once per shell session. </p>"},{"location":"Setup/Git/git_setup/#configuring-a-commit-message","title":"Configuring a Commit Message","text":"<p>Lisa Wolderisksen has written an impeccable git commit template that we will use.</p> <pre><code># Title: Summary, imperative, start upper case, don't end with a period\n# No more than 50 chars. #### 50 chars is here:  #\n\n# Remember blank line between title and body.\n\n# Body: Explain *what* and *why* (not *how*). Include task ID (Jira issue).\n# Wrap at 72 chars. ################################## which is here:  #\n\n\n# At the end: Include Co-authored-by for all contributors. \n# Include at least one empty line before it. Format: \n# Co-authored-by: name &lt;user@users.noreply.github.com&gt;\n#\n# How to Write a Git Commit Message:\n# https://chris.beams.io/posts/git-commit/\n#\n# 1. Separate subject from body with a blank line\n# 2. Limit the subject line to 50 characters\n# 3. Capitalize the subject line\n# 4. Do not end the subject line with a period\n# 5. Use the imperative mood in the subject line\n# 6. Wrap the body at 72 characters\n# 7. Use the body to explain what and why vs. how\n</code></pre> <p>To add this to your global Git setting, open a new file with:</p> <p><code>nano ~/.gitmessage</code></p> <p>Copy the above text to the file (<code>Ctrl+ V</code>) and then save and exit by typing <code>Ctrl + o</code> and then <code>Ctrl + x</code>.</p> <p>Next, tell Git to use the template file for all commits by using the command:</p> <pre><code>git config --global commit.template ~/.gitmessage\n</code></pre> <p>Now, you can leave out the option <code>-m</code> in your <code>git commit</code> command. </p> <p>Try saving saving some work in a repo and then running:</p> <pre><code>git add .\ngit commit\n</code></pre> <p>You'll now see the custom Git template open in Nano!</p>"},{"location":"Setup/Git/git_setup/#saving-our-ssh-key-password-per-shell-session","title":"Saving our SSH key Password per Shell Session","text":"<p>We can automate this process in two steps:</p> <ol> <li>Configure Bash to start ssh-agent on shell session open</li> <li>Configure the ssh service to add the key to the agent after the initial use and password prompt</li> </ol>"},{"location":"Setup/Git/git_setup/#configuring-bash-to-start-ssh-agent-on-open","title":"Configuring Bash to start ssh-agent on open","text":"<p>We can configure bash to start up <code>ssh-agent</code> on open. To do so, we need to edit our <code>.bashrc</code> (short for bash read command) which is a script that runs every time we start a shell session. Open your <code>.bashrc</code> file with nano. </p> <pre><code>nano ~/.bashrc\n</code></pre> <p>Paste the following command into the end of the document, save, and close the file. </p> <pre><code>#starting the ssh-agent - but suppressing the output\neval `ssh-agent` &gt; /dev/null\n</code></pre> <p>On a side note, <code>&gt; /dev/null</code> is a really useful command that redirects the standard output ( <code>stdout</code>)  to the null device <code>/dev/null</code>.</p> <p>Close and restart the terminal.</p> <p>You can confirm that <code>ssh-agent</code> is running by typing <code>echo \"$SSH_AUTH_SOCK\"</code>.</p> <pre><code>$ echo \"$SSH_AUTH_SOCK\"\n/tmp/ssh-XXXXXX2dfjZo/agent.13048\n</code></pre>"},{"location":"Setup/Git/git_setup/#automatically-adding-our-ssh-key-to-the-ssh-agent","title":"Automatically adding our SSH key to the ssh-agent","text":"<p>We can add a <code>config</code> file to our <code>~/.ssh</code> folder in order to set some settings for SSH communication. </p> <pre><code>nano ~/.ssh/config\n</code></pre> <p>In the config file you can add the following lines. This configuration adds a key, once used to the ssh-agent for all hosts. If you wanted to further specify this behavior, you could change the asterisk to the host of your choice.</p> <pre><code>Host *\n  AddKeysToAgent yes\n</code></pre> <p>Save the file and close. And there we have it! You will only have to enter your password once per shell session when working with Git!  </p>"},{"location":"Setup/Python/conda_tensorflow_setup/","title":"TensorFlow Setup in Miniconda Using an Nvidia GPU","text":""},{"location":"Setup/Python/conda_tensorflow_setup/#references","title":"References","text":"<p>After trying to follow a bunch of Medium articles, I figured this out by referring solely to the official documentation. Lesson learned. I've followed the following guides (as of November, 2023):</p> <ul> <li>Install TensorFlow with Pip</li> <li>CUDA on WSL User Guide</li> </ul>"},{"location":"Setup/Python/conda_tensorflow_setup/#assumptions","title":"Assumptions","text":"<p>These notes assume you have an Nvidia GPU that uses CUDA 3.5 or higher. You can check your card here.</p>"},{"location":"Setup/Python/conda_tensorflow_setup/#install-the-most-up-to-date-nvidia-drivers-on-the-windows-side","title":"Install the Most Up to Date Nvidia Drivers on the Windows Side","text":"<p>NOTE: The CUDA instructions above refer to the Game Ready driver. I actually installed the Studio Driver and everything is working AOK. The studio driver is probably what most designers would install, so this is worth mentioning.</p> <p>Download the most current Nvidia driver for your GPU here. Follow the prompts and wait until installation is complete. Restart your computer. If you don't the driver will not pick up on the WSL2 side and will return <code>segmentation fault</code> from the command <code>nvidia-smi</code> that we will use in the next step.</p> <p>IMPORTANT NOTE: Do not install any Nvidia drivers within WSL2. From Nvidia's documentation:</p> <p>Once a Windows NVIDIA GPU driver is installed on the system, CUDA becomes available within WSL 2. The CUDA driver installed on Windows host will be stubbed inside the WSL 2 as <code>libcuda.so</code>, therefore users must not install any NVIDIA GPU Linux driver within WSL 2.</p> <p>Once you have installed the Nvidia driver on the Window's side, you can confirm that it is working within WSL2 by typing <code>nvidia-smi</code>. You should see something similar to this:</p> <pre><code>thomas@TI83:~$ nvidia-smi\nWed Nov  1 22:54:23 2023\n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.120                Driver Version: 537.58       CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 2070        On  | 00000000:01:00.0  On |                  N/A |\n|  0%   41C    P8              24W / 175W |    670MiB /  8192MiB |      4%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n\n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|    0   N/A  N/A        23      G   /Xwayland                                 N/A      |\n+---------------------------------------------------------------------------------------+\n</code></pre>"},{"location":"Setup/Python/conda_tensorflow_setup/#install-cuda-toolkit","title":"Install CUDA Toolkit","text":"<p>The commands for installation can be found here. Copy each line, one by one. Ensure that you are selecting the following platform options:</p> <ul> <li>OS = Linux</li> <li>Architecture = x86_64</li> <li>Distribution = WSL-Ubuntu</li> <li>Version = 2.0</li> <li>Installer Type = deb(network) (local is also fine but you'll just have to delete the installer file afterwards)</li> </ul> <p>Make sure that you are installing this outside of a Conda environment. This is a WSL2 wide install.</p>"},{"location":"Setup/Python/conda_tensorflow_setup/#create-a-conda-environment-for-your-tensorflow-project","title":"Create a Conda environment for your TensorFlow project","text":"<p>Follow the steps in the miniconda_setup notes.</p>"},{"location":"Setup/Python/conda_tensorflow_setup/#upgrade-pip","title":"Upgrade Pip","text":"<p>We've been talking Conda throughout these notes, but pip is another package manager. In fact, it is the original package manager. We are going to use pip to install TensorFlow (and the related CUDA / cuDNN libraries) in one easy command. To upgrade pip (inside a Conda environment):</p> <pre><code>pip install --upgrade pip\n</code></pre>"},{"location":"Setup/Python/conda_tensorflow_setup/#install-tensorflow","title":"Install TensorFlow","text":"<p>Within your Conda environment, we can install TensorFlow (and the related CUDA / cuDNN libraries) like so:</p> <pre><code>pip install tensorflow[and-cuda]\n</code></pre>"},{"location":"Setup/Python/conda_tensorflow_setup/#verify-the-installation","title":"Verify the Installation","text":"<p>Still within our Conda environment, we can verify that we've successfully installed TensorFlow with a GPU setup with the following command:</p> <pre><code>python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n</code></pre> <p>If you have successfully enabled your GPU to work with TensorFlow, you will get an output similar to below. Note that, according to experts, TensorFlow vomits a lot of useless crap at you, and we are really only concerned with the last line that's output from this command.</p> <pre><code># the command\n(env)thomas@TI83:~/repos/tfTest$ python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n\n#start of crap vomiting\n2023-11-02 23:42:44.606803: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2023-11-02 23:42:44.606844: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2023-11-02 23:42:44.608321: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2023-11-02 23:42:44.723861: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-11-02 23:42:47.074345: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\nYour kernel may have been built without NUMA support.\n2023-11-02 23:42:47.096695: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\nYour kernel may have been built without NUMA support.\n2023-11-02 23:42:47.096754: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\nYour kernel may have been built without NUMA support.\n# end of crap vomiting\n\n#the important thing\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n</code></pre> <p>If you see a <code>PhysicalDevice</code> within that final Python list, you are good to go!</p>"},{"location":"Setup/Python/conda_tensorflow_setup/#troubleshooting-if-something-goes-wrong","title":"Troubleshooting if Something Goes Wrong","text":"<p>As of November 3, 2023, it appears that Python 3.11 does not support the <code>[and-cuda]</code> option. In other words, when installing TensorFlow in a Python 3.11 Conda environment, you will not be able to install all the related CUDA drivers with the handy <code>pip install tensorflow[and-cuda]</code> command. You can confirm this by looking for this line buried within the TensorFlow install output:</p> <pre><code>#lots of stuff before this\nCollecting tensorflow[and-cuda]\n  Using cached tensorflow-2.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\nWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda' # &lt;--- THIS IS THE LINE YOU ARE LOOKING FOR\nCollecting gast&lt;=0.4.0,&gt;=0.2.1 (from tensorflow[and-cuda])\n  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\nCollecting keras&lt;2.14,&gt;=2.13.1 (from tensorflow[and-cuda])\n#lots of stuff after this\n</code></pre> <p>This is a reported and reproducible error.</p> <p>If you have just created a new directory for your project and are just beginning to set things up, it's easiest to just delete the current environment and start again using Python 3.10.</p> <pre><code>(env)thomas@TI83:~/repos/ai_for_coders/01_intro$ conda deactivate\nthomas@TI83:~/repos/ai_for_coders$ cd ..\nthomas@TI83:~/repos/ai_for_coders$ rm 01_intro/ -r\nthomas@TI83:~/repos/ai_for_coders$ mkdir 01_intro\nthomas@TI83:~/repos/ai_for_coders$ cd 01_intro/\nthomas@TI83:~/repos/ai_for_coders/01_intro$ conda create --prefix ./env python=3.10\n</code></pre> <p>If you need to downgrade without deleting your environment, you can downgrade Python:</p> <pre><code>(env)thomas@TI83:~/repos/ai_for_coders/01_intro$ conda install python=3.9.0\n</code></pre> <p>I noticed that TensorFlow was uninstalled when I downgraded Python. You can confirm this by using the command <code>conda list</code>:</p> <pre><code>(env)thomas@TI83:~/repos/ai_for_coders/01_intro$ conda list\n# packages in environment at /home/thomas/repos/ai_for_coders/01_intro/env:\n#\n# Name                    Version                   Build  Channel\n_libgcc_mutex             0.1                        main\n_openmp_mutex             5.1                       1_gnu\nbzip2                     1.0.8                h7b6447c_0\nca-certificates           2023.08.22           h06a4308_0\nld_impl_linux-64          2.38                 h1181459_1\nlibffi                    3.3                  he6710b0_2\n# ... more stuff below but NO TENSORFLOW\n</code></pre> <p>If this is the case, reinstall TensorFlow as before. </p> <p>Otherwise, if it does appear, test to see if it is working by verifying your GPU (as above). If TensorFlow is installed but does not work after downgrading Python, your best bet is use <code>pip uninstall tensorflow</code> and then repeat, <code>pip install tensorflow[and-cuda]</code>. If this doesn't work, I'd probably just delete the environment and recreate it without touching the actual code.</p>"},{"location":"Setup/Python/miniconda_setup/","title":"Miniconda Setup","text":""},{"location":"Setup/Python/miniconda_setup/#references","title":"References","text":"<p>I learnt ALOT from The Carpentries Incubator's Introduction to Conda for Data Scientists. A lot of my set up was gleaned from their material.</p>"},{"location":"Setup/Python/miniconda_setup/#installing-miniconda","title":"Installing Miniconda","text":"<p>As per the Miniconda docs, we can 'quickly and quietly' install the latest 64-bit version with a few commands.</p> <pre><code>mkdir -p ~/miniconda3\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\nbash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\nrm -rf ~/miniconda3/miniconda.sh\n</code></pre> <p>We can then initialize Miniconda for our Bash shell:</p> <pre><code>~/miniconda3/bin/conda init bash\n</code></pre> <p>We need to close our terminal session and reopen a new terminal for the effect to finalize. Once you've reopened your terminal, you'll see that Miniconda, by default, initializes and activates the default environment <code>base</code>. </p>"},{"location":"Setup/Python/miniconda_setup/#disabling-conda-base-auto-activation","title":"Disabling Conda Base Auto-Activation","text":"<p>The <code>base</code> in parentheses indicates we're currently in that environment. We want to avoid installing additional packages into our base environment. It's best practice to setup a new environment for each project.</p> <pre><code>(base) thomas@TI83:~$\n</code></pre> <p>What's more, I prefer no to have Miniconda initialize automatically. To turn-off this behavior, run the following command which modifies Miniconda's configuration file <code>.condarc</code>.</p> <pre><code>conda config --set auto_activate_base false\n</code></pre>"},{"location":"Setup/Python/miniconda_setup/#activating-conda-deactivating-conda","title":"Activating Conda / Deactivating Conda","text":"<p>We can use <code>conda activate</code> to activate Conda in the <code>base</code> environment, and <code>conda deactivate</code> to deactivate the current Conda environment.</p> <pre><code>thomas@TI83:~$ conda activate\n(base) thomas@TI83:~$ conda deactivate\nthomas@TI83:~$\n</code></pre>"},{"location":"Setup/Python/miniconda_setup/#creating-environments-with-specific-locations","title":"Creating Environments with Specific Locations","text":"<p>One thing that has kept me from exploring Conda for quite a while is that I liked how easily pip creates an environment in the current directory, and how this is default behavior. By default Conda environments are created in the <code>envs/</code> folder of the <code>miniconda3</code> directory.</p> <p>It turns out, I'm just a bit lazy, and it is pretty easy to do this in Conda as well.</p> <pre><code>thomas@TI83:~$ cd repos/ # move to my repos directory\nthomas@TI83:~/repos$ mkdir condaTest # make a new directory for my project 'condaTest'\nthomas@TI83:~/repos$ cd condaTest/ # move to the project directory\n\n#AND HERE LIES THE IMPORTANT STEP - ENVIRONMENT CREATION\nthomas@TI83:~/repos/condaTest$ conda create --prefix ./env python=3.11\n</code></pre> <p>The last command can be broken down as:</p> <ul> <li><code>conda create --prefix ./env</code> - This creates an environment in a new sub-directory <code>./env</code>. </li> <li><code>python=3.11</code> - This specifies the version of Python we want to use in this environment.</li> </ul> <p>If we added a few files to the project, our folder structures looks like this.</p> <pre><code>thomas@TI83:~/repos/condaTest$ tree -L 2\n.\n\u251c\u2500\u2500 code.py\n\u251c\u2500\u2500 env\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 bin\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 compiler_compat\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 conda-meta\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 include\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lib\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 man\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 share\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ssl\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 x86_64-conda-linux-gnu\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 x86_64-conda_cos7-linux-gnu\n\u2514\u2500\u2500 notebook.ipynb\n</code></pre>"},{"location":"Setup/Python/miniconda_setup/#activating-environments-that-were-created-in-a-specific-directory","title":"Activating Environments that were Created in a Specific Directory","text":"<p>To activate this environment you would move to the directory where the project is located - in this case <code>condaTest</code> - and then use the command <code>conda activate ./env</code>.</p> <pre><code>thomas@TI83:~$ cd repos/condaTest/\nthomas@TI83:~/repos/condaTest$ conda activate ./env\n(/home/thomas/repos/condaTest/env) thomas@TI83:~/repos/condaTest$\n</code></pre>"},{"location":"Setup/Python/miniconda_setup/#changing-your-environments-name-from-that-long-absolute-path-to-something-manageable","title":"Changing your Environment's Name from that Long Absolute Path to Something Manageable","text":"<p>In the above example, our environment's name is <code>(/home/thomas/repos/condaTest/env)</code>. That is annoyingly long. You can change this behavior on a Conda-wide level by running the following command that edits your aforementioned <code>~/.condarc</code> properties file.</p> <pre><code>$ conda config --set env_prompt '({name})'\n</code></pre> <p>Now the previous example will look like this:</p> <pre><code>thomas@TI83:~$ cd repos/condaTest/\nthomas@TI83:~/repos/condaTest$ conda activate ./env\n(env)thomas@TI83:~/repos/condaTest$\n</code></pre>"},{"location":"Setup/VSCode/keras_gotcha/","title":"Keras gotcha","text":""},{"location":"Setup/VSCode/keras_gotcha/#setting-up-intellisense-for-tensorflow-keras","title":"Setting up intellisense for TensorFlow / Keras","text":"<p>https://stackoverflow.com/questions/73496946/vscode-autocomplete-and-suggestion-intellisense-doesnt-work-for-tensorflow-an</p>"}]}